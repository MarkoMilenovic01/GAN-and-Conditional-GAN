# ğŸ§  MNIST GAN & Conditional GAN (cGAN) â€” PyTorch

This repository contains **clean, from-scratch PyTorch implementations** of:

* **Vanilla GAN** (Generative Adversarial Network)
* **Conditional GAN (cGAN)**

Both models are trained on the **MNIST handwritten digits dataset** and include:

* training scripts
* model checkpoints
* evaluation utilities
* generated image grids
* loss curve visualizations

The project is intended for **learning, experimentation, and academic demonstration** of GAN fundamentals and conditional generation.

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py              # MNIST DataLoader
â”‚   â”œâ”€â”€ model.py                # Vanilla GAN (Generator + Discriminator)
â”‚   â”œâ”€â”€ advanced_model.py       # Conditional GAN (cGenerator + cDiscriminator)
â”‚   â”œâ”€â”€ train_gan.py            # Train vanilla GAN
â”‚   â”œâ”€â”€ train_cgan.py           # Train conditional GAN
â”‚   â”œâ”€â”€ eval_gan.py             # GAN evaluation & evolution
â”‚   â””â”€â”€ eval_cgan.py            # cGAN digit-conditioned evaluation
â”‚
â”œâ”€â”€ gan_results/                # GAN generated samples per epoch
â”œâ”€â”€ gan_checkpoints/            # GAN model checkpoints
â”œâ”€â”€ gan_evaluation/             # GAN evaluation outputs
â”‚
â”œâ”€â”€ cgan_results/               # cGAN generated samples & losses
â”œâ”€â”€ cgan_checkpoints/           # cGAN model checkpoints
â”‚
â”œâ”€â”€ gan_losses.png              # GAN loss curves
â”œâ”€â”€ cGAN_losses.png             # cGAN loss curves
â”‚
â””â”€â”€ README.md
```

---

## ğŸ§ª Models Overview

### ğŸ”¹ Vanilla GAN

* Input: random noise vector $z \sim \mathcal{N}(0, 1)$
* Output: generated MNIST-like digit images
* Unconditional generation

**Generator**

* Fully connected layer â†’ reshape
* Transposed convolutions (upsampling)
* Sigmoid output in $[0,1]$

**Discriminator**

* Convolutional layers
* Binary classification: real vs fake

---

### ğŸ”¹ Conditional GAN (cGAN)

The cGAN conditions image generation on **digit labels (0â€“9)**.

**Key idea:**

$$
G(z, y) \rightarrow x \quad , \quad D(x, y) \rightarrow {0,1}
$$

* Generator input: **noise + one-hot encoded label**
* Discriminator input: **image + label map channel**

This enables **controlled generation**, e.g. â€œgenerate only digit 5â€.

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Install dependencies

```bash
pip install torch torchvision matplotlib
```

### 2ï¸âƒ£ Train Vanilla GAN

```bash
cd src
python train_gan.py
```

Outputs:

* `gan_results/epoch_*.png`
* `gan_checkpoints/*.pth`
* `gan_losses.png`

---

### 3ï¸âƒ£ Train Conditional GAN

```bash
cd src
python train_cgan.py
```

Outputs:

* `cgan_results/epoch_*.png`
* `cgan_checkpoints/*.pth`
* `cGAN_losses.png`

---

## ğŸ“Š Training Loss Curves

### GAN Losses

![GAN Loss Curves](gan_losses.png)

### cGAN Losses

![cGAN Loss Curves](cGAN%20losses.png)

---

## ğŸ–¼ï¸ Generated Samples

### ğŸ² Vanilla GAN â€” Final Samples

![GAN Final Samples](gan_results/final.png)

---

### ğŸ”¢ Conditional GAN â€” Digit-Specific Generation

Example: **digit 5 only**

![cGAN Evaluation](cgan_results/eval.png)

---

## ğŸ”„ Generator Evolution (GAN)

The same noise vector is passed through generators saved at different epochs to visualize training progression:

```
gan_evaluation/evolution_epoch_0.png
gan_evaluation/evolution_epoch_50.png
gan_evaluation/evolution_epoch_100.png
```

This shows how structure gradually emerges from noise.

---

## ğŸ¯ Key Learning Outcomes

* Understand GAN vs cGAN architectures
* Learn conditional generation using labels
* Implement stable GAN training loops
* Visualize generator evolution over time
* Work with PyTorch DataLoaders & checkpoints

---

## ğŸ› ï¸ Technologies Used

* Python
* PyTorch
* TorchVision
* Matplotlib
* MNIST Dataset

---

## ğŸ“Œ Notes

* Designed for **educational clarity**, not heavy optimization
* Easily extensible to other datasets (Fashion-MNIST, CIFAR-10)
* Clear separation between **model**, **training**, and **evaluation**

---

## ğŸ“œ License

This project is open for **academic and educational use**.

---

â­ If you find this useful, feel free to star the repository!

